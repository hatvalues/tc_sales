```{r prologue, include=FALSE}
knitr::opts_chunk$set(warning = FALSE
                      , message = FALSE
                      , echo = FALSE
                      )

knitr::opts_template$set(
  fig.wide = list(fig.height = 4.5, fig.width = 8, fig.align='center')
  , fig.wideX = list(fig.height = 3, fig.width = 9, fig.align='center')
  , fig.relaxed = list(fig.height = 6, fig.width = 8, fig.align='center')
  , fig.tile = list(fig.height = 3, fig.width = 3, fig.align='center')
)

par(mar = c(4,3,3,1))
```

```{r initial_load}
library(readr)
library(dplyr)
library(lattice)
library(vcd)
library(BayesianFirstAid)
source("TC_Theme.R")
link <- "TC_SalesQuota.csv"
raw.data <- read_csv(link) %>%
  mutate(Group = as.factor(Group)
            , KSales = Sales/1000
            , KQuota = Quota/1000
            , Sales = as.integer(Sales)
            , Quota = as.integer(Quota)
            , MetTarget = Attainment >= 100)

get.col <- function(colnm, grp) {
  as.matrix(raw.data %>% filter(Group == grp) %>% dplyr::select(colnm))
}
set.seed(12321)
```
# Statistical Analysis of Sales Data

##### Julian Hatwell
##### `r format(as.Date("2016-08-04"), "%b %Y")`

## Introduction
The client's sales department is organised into groups A and B. Members of Group B are set much lower quotas (sales targets) on average, reflecting a difference in difficulty to sell to group B customers.

## Business Problem
Is there any difference performance between the two groups? What (if any) anomalies are present? Make recommendations based on the findings.

## Methodology
We will present the descriptive statistics. We will then analyse groups using a Bayesian statistical test. Bayesian methods are preferred for this analysis, because the data is a complete census (the entire sales department). The interpretation is more intuitive and we do not intend to make inferences about a larger population. Furthermore, checking assumptions and diagnostics for packaged Bayesian models is much less time consuming.

### Descriptive
The following listing shows the top 6 rows of the data file followed by a standard summary for the whole sample, and separately by group.

```{r descr_stats, opts.label='fig.wide'}
k.data <- raw.data %>% dplyr::select(-Sales, -Quota)
head(k.data)
cat("Both Groups")
summary(k.data)
cat("Group A only")
summary(k.data %>% filter(Group == "A"))
cat("Group B only")
summary(k.data %>%  filter(Group == "B"))
cat("Quota to Sales Correlation")
with(raw.data, cor(KSales, KQuota))
xyplot(KSales~KQuota, data=raw.data
       , groups = Group
       , par.settings = MyLatticeTheme)
```

#### Remarks
As expected, given the brief, Group B has lower Quota and Sales than Group A. There appears to be a very strong correlation between Quota and Sales. This correlation suggests that whoever is setting the quota (targets) at the start of the sales year has an uncanny grasp of the annual sales process.

### Differences in Performance Within Groups
We will consider the two groups separately, given the known difference *between* groups already descibed.

For those who made their targets compared to those who didn't, it's useful to know how much their quotas were influential. A boxplot helps to visualise this for the two groups:

```{r boxplots, opts.label='fig.wideX'}
mns <- round(tapply(raw.data$KQuota, list(raw.data$Group, raw.data$MetTarget), mean),2)
mns <- mns[, c("TRUE", "FALSE")]
bwplot(KQuota ~ factor(MetTarget, levels = c(TRUE, FALSE)) | Group
       , data = raw.data
       , scales = list(format = list(digits = 10))
       , par.settings = MyLatticeTheme
       , strip = MyLatticeStrip
       , xlab = "Met target"
       , ylab = "Quota (1000's units)"
       , main = "Group performance to targets"
       , panel = function(x, y, ...) {
         panel.bwplot(x, y, ...)
         panel.average(x, y
                       , lwd = 2
                       , lty = 1
                       , col = myPalDark[1]
                       , ...)
         panel.text(1:2
                    , mns[which.packet(),] + 5
                    , mns[which.packet(),]
                    , col = myPalDark[1]
                    , cex = 1.1
                    , fontface = "bold"
                    , ...)
       }
)
```

In Group A, there is no real difference in the mean Quotas ($\approx$ 0.1K sales quota units) between those who met their target and those who didn't. For Group B, this difference is notably $\approx$ -2.36K sales quota units i.e. somewhat lower among those who met their target than those who did not. 

However, with such a large range of quotas (`r round(range(get.col("KQuota","B")[get.col("MetTarget", "B")]), 2)`), is this difference important? A Bayesian t-test can help to answer this question. For comparison, we show the test results for both groups.

### Bayesian t-test Group A

```{r b_t_tests_A, cache=TRUE}
tta <- bayes.t.test(get.col("KQuota","A")[get.col("MetTarget", "A")]
            , get.col("KQuota","A")[!get.col("MetTarget", "A")]
            , var.equal = TRUE)

tta$x_name <- "Group A: Met Target"
tta$y_name <- "Group A: Target not Met"

plot(tta)
```

The bottom two charts show the posterior (distribution) of the mean difference (Group A: Met Target vs Group A: Target not Met). We can see the posterior is centred very close to zero difference.

### Bayesian t-test Group B

```{r b_t_tests_B, cache=TRUE}
ttb <- bayes.t.test(get.col("KQuota","B")[get.col("MetTarget", "B")]
            , get.col("KQuota","B")[!get.col("MetTarget", "B")]
            , var.equal = TRUE)

ttb$x_name <- "Group B: Met Target"
ttb$y_name <- "Group B: Target not Met"

plot(ttb)
```

The bottom two charts show the posterior distribution of the mean difference (Group B: Met Target vs Group B: Target not Met). We can see the posterior is centred at `r round(ttb$stats["mu_diff", "median"], 2)` which aligns with the above box plot. The effect size (relative to the variance) is considered medium at `r round(ttb$stats["eff_size", "median"], 2)`. Zero is inside the credible interval, but there is a $\approx 95\%$ that the Met Target sub group have a lower median target than the Target not Met sub group.

#### Remarks
The obvious difference *between* groups is expected, as per the client brief (different customer segments), so the groups were considered separately here. A Bayesian t-test confirms the visual assessment that there is no significant difference in the median quotas set for the sub-groups in Group A (those who met their target vs those who missed it). One the other hand, we have evidence to suggest that this is not the case for Group B. Those who met their targets (taken as a group) may have had more slightly more achievable targets than those who did not. Note that the evidence is borderline credible.

A standard t-test (not shown) produces a very similar result but the difference in Group B would be reported as non-significant based on the p-values (p = 0.056). Again, we might consider this a borderline result but the Bayesian interpretation is more intuitive.

A visual analysis of the MCMC diagnostics (not shown) revealed no problems with the test convergence.

### Closing Remarks
In light of this finding we suggest a review of the quota setting for group B, in order to ensure fairness across the team.

## Appendix: Code
```{r initial_load, echo=TRUE, eval=FALSE}
```

```{r descr_stats, echo=TRUE, eval=FALSE}
```

```{r boxplots, echo=TRUE, eval=FALSE}
```

```{r b_t_tests_A, echo=TRUE, eval=FALSE}
```

```{r b_t_tests_B, echo=TRUE, eval=FALSE}
```

