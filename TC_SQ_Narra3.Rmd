```{r prologue, include=FALSE}
library(knitr)
library(readr)
library(dplyr)
library(lattice)
library(ggplot2)
library(vcd)
library(MCMCpack)
library(coda)
library(gridExtra)
knitr::opts_chunk$set(warning = FALSE
                      , message = FALSE
                      , echo = FALSE
                      )

knitr::opts_template$set(
  fig.wide = list(fig.height = 4.5, fig.width = 8, fig.align='center')
  , fig.wideX = list(fig.height = 3, fig.width = 9, fig.align='center')
  , fig.relaxed = list(fig.height = 6, fig.width = 8, fig.align='center')
  , fig.tile = list(fig.height = 3, fig.width = 3, fig.align='center')
)

source("~/Documents/github/R_Themes/TC_Theme.R")

par(mar = c(4,3,3,1))
```

```{r Initial_Load}
link <- "~/Documents/github/TC_SalesQuotas/TC_SalesQuota.csv"
raw.data <- read_csv(link) %>%
  transmute(Group = as.factor(Group)
            , KSales = Sales/1000
            , KQuota = Quota/1000
            , MetTarget = Attainment >= 100)

get.col <- function(colnm, grp) {
  as.matrix(raw.data %>% filter(Group == grp) %>% dplyr::select(colnm))
}
set.seed(12321)
```
# Statistical Analysis of Sales Data

##### Julian Hatwell
##### `r format(Sys.time(), "%b %Y")`

## Introduction
Within the sales department, sales agents may be a member of group A or group B. The group membership determines the customer segment that the sales agent will work on. Group B are set much lower quotas (sales targets) on average, reflecting a difference in difficulty to sell to group B customers.

## Brief
Determine if there is any difference between group performance, what (if any) anomalies are present, and to make any recommendations based on the findings.

## Methodology
We will perform basic descriptive statistics on the data set. We will then use Bayesian regression methods to determine whether there is any difference between the goups' performance. Bayesiam methods are preferred for this analysis, because the intention is to estimate the most likely parameter values from a complete census (the entire sales department) rather than making inference to a larger population. Furthermore, checking assumptions and diagnostics for simple Bayesian regression models is much less time consuming.

### Descriptive Statistics
The following listing shows the top 6 rows of the data file followed by a standard summary for the whole sample, and separately by group.

```{r DescrStats, opts.label='fig.wide'}
head(raw.data)
summary(raw.data)
summary(raw.data %>% filter(Group == "A"))
summary(raw.data %>% filter(Group == "B"))
cat("Quota to Sales Correlation")
with(raw.data, cor(KSales, KQuota))
xyplot(KSales~KQuota, data=raw.data
       , groups = Group
       , par.settings = MyLatticeTheme)
```

#### Remarks
As expected, given the brief, Group B has lower Quota and Sales than Group A. There appears to be a very strong correlation between Quota and Sales. This correlation suggests that whoever is setting the quota (targets) at the start of the sales year has an uncanny grasp of the annual sales process.

### Differences in Performance Within Groups
For those who made their targets compared to those who didn't, it's useful to know how much their quotas were influential. A boxplot helps to visualise this for the two groups:

```{r boxplot_MetTarget, opts.label='fig.wideX'}
mns <- round(tapply(raw.data$KQuota, list(raw.data$Group, raw.data$MetTarget), mean),2)
bwplot(KQuota ~ factor(MetTarget) | Group
       , data = raw.data
       , scales = list(format = list(digits = 10))
       , par.settings = MyLatticeTheme
       , strip = MyLatticeStrip
       , xlab = "Met target"
       , ylab = "Quota (1000's units)"
       , main = "Group performance to targets"
       , panel = function(x, y, ...) {
         panel.bwplot(x, y, ...)
         panel.average(x, y
                       , lwd = 2
                       , lty = 1
                       , col = myPalDark[1]
                       , ...)
         panel.text(1:2
                    , mns[which.packet(),] + 5
                    , mns[which.packet(),]
                    , col = myPalDark[1]
                    , cex = 1.1
                    , fontface = "bold"
                    , ...)
       }
)
```

```{r wlxForQuotaTarget}
tta <- t.test(get.col("KQuota","A")[get.col("MetTarget", "A")]
            , get.col("KQuota","A")[!get.col("MetTarget", "A")])

tta$data.name <- "Group A: Target not Met / Target Met"

ttb <- t.test(get.col("KQuota","B")[get.col("MetTarget", "B")]
            , get.col("KQuota","B")[!get.col("MetTarget", "B")])

ttb$data.name <- "Group B: Target not Met / Target Met"

tta
ttb
```

#### Remarks
The obvious difference between groups is expected, as per the brief (different customer segments), so the groups are considered separately here. A t-test confirms the visual assessment that there is no significant difference in the distribution of quotas set for those who eventually missed or hit their targets (in either group). The nature of this test means that we could extrapolate the result to a larger population, if one existed. However, this is essentially a census of a whole population (the sales department) so will extend our analysis with Bayesian modeling to determine a credible interval for the underlying parameters, given this fixed data.

### Tests for Between Group Differences in Attainment

#### Log Odds Ratio Test
```{r lor, opts.label='fig.tile' }
with(raw.data, fourfold(table(MetTarget, Group)))
```

#### Remarks
This is a non-significant result, showing that the ratio of Target not Met : Target Met is not different between the groups. This test does not control for quota as a covariate.

#### Bayesian Logistic Regression
We create a series Bayesian logistic models to regress the boolean outcome "Met Target" on the Group and KQuota variables, including testing for interactions (different slopes).

```{r model3els, opts.label='fig.tile'}
model1 <- MCMCregress(I(MetTarget * 1) ~ 1,
                      data=raw.data, b0=c(0),
                      B0=c(1e-6),
                      marginal.likelihood="Chib95", mcmc=10000)

model2 <- MCMCregress(I(MetTarget * 1) ~ KQuota + Group,
                      data=raw.data, b0=c(0, 0, 0),
                      B0=c(1e-6, 1e-6, 1e-6),
                      marginal.likelihood="Chib95", mcmc=10000)

model3 <- MCMCregress(I(MetTarget * 1) ~ KQuota * Group,
                      data=raw.data, b0=c(0, 0, 0, 0),
                      B0=c(1e-6, 1e-6, 1e-6, 1e-6),
                      marginal.likelihood="Chib95", mcmc=10000)

BF <- BayesFactor(model1, model2, model3)
BF$BF.call
BF$BF.log.mat
```

#### Remarks
Visual inspection of the MCMC chains and posterior distributions revealed no abnormalities.

The Bayes Factor analysis shows that the model that allows for an interaction term has a very large Bayes Factor compared to either of the simpler models. The posterior distributions for the parameters are as follows:

```{r model3els_conclusions, opts.label='fig.wide'}
summary(model3)$quantiles[, c(1, 3, 5)]
densplot(model3[, 1])
abline(v=0, lty=2, lwd=0.5, col = myPalContrasts[4])
cat(paste(mean(model3[, 1] >= 0.0)
          , "of this distribution is greater than zero"))
densplot(model3[, 2])
abline(v=0, lty=2, lwd=0.5, col = myPalContrasts[4])
cat(paste(mean(model3[, 2] >= 0.0)
          , "of this distribution is greater than zero"))
densplot(model3[, 3])
abline(v=0, lty=2, lwd=0.5, col = myPalContrasts[4])
cat(paste(mean(model3[, 3] >= 0.0)
          , "of this distribution is greater than zero"))
densplot(model3[, 4])
abline(v=0, lty=2, lwd=0.5, col = myPalContrasts[4])
cat(paste(mean(model3[, 4] >= 0.0)
          , "of this distribution is greater than zero"))
```

From these results, we can see that zero is centrally located in the credible interval for the group A slope (quota "main" effect), so this can be assumed to be negligable. The posterior distributions for the group B intercept and slope parameters also contain zero but with >90% of the interval above or below zero respectively. We could interpret this informally as an indication that of how likely it is that group B members with a low quota have a greater probability of hitting target - the negative slope indicating that increasing quotas decreases this probability. In situation, it could be said that the lowest quotas are not as challenging, but only for group B members. The following plot illustrates this result by performing the inverse logit on the MCMC chains with these parameters. The median prediction and 95% credible ranges are shown for each instance and redundant points show the true outcomes of MetTarget True/False and the top/bottom of the panel for the group B members.

```{r pred_plot, opts.label='fig.wide'}
predict_mcmc_one <- function(x) {
  model3[, 1] + model3[, 2] * raw.data$KQuota[x] +
  model3[, 3] * (raw.data$Group[x] == "B") + 
  model3[, 4] * raw.data$KQuota[x] * (raw.data$Group[x] == "B")
}
preds <- t(sapply(1:nrow(raw.data), predict_mcmc_one))
preds_quants <- t(apply(exp(preds)/ (1 + exp(preds)), 1, quantile))
plot(preds_quants[, 3]~raw.data$KQuota, col = myPalContrasts[as.numeric(raw.data$Group)]
     , pch=20, cex = 0.75
     , ylim= c(0.3, 0.8)
     , xlab="Quota"
     , ylab="Modelled Probability of Meeting Target")
segments(x0 = raw.data$KQuota, y0 = preds_quants[, 1], x1 = raw.data$KQuota, y1 = preds_quants[, 5]
         , col = myPalContrasts[as.numeric(raw.data$Group)]
         , lwd = 0.5)
legend("bottomright", legend = paste("group", c("A", "B"), " - median and HDI"), col = myPalContrasts[1:2], pch = 20, lty = 1, cex=0.75)
abline(0.5, 0, lty=2, lwd=0.5)
points(0.3 + 0.5*MetTarget~KQuota, cex = 0.4
       , data=raw.data, pch = as.character(raw.data$MetTarget)
       , col = myPalContrasts[as.numeric(raw.data$Group)]
       , subset = raw.data$Group == "B")
```

In light of this finding we suggest that it is feasible that individuals in group B with the lowest quotas may be working under a slightly less challenging regime than others in their group and in the department as a whole. The evidence for this is far from conclusive, but a review of the quota setting for group B may be advisable.

### Closing Remarks
This was a fairly detailed analysis for such a simple dataset. Using Bayesian statistics allowed us to draw conclusions about the closed population directly. This is in contrast with classical (frequentist) statistics that are typically used to make inferences from a sample to a larger population.